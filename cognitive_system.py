# C:\Users\m.2 SSD\Desktop\lastagent\agent006\cognitive_system.py
"""
AutonomousCognitiveSystem (ACS) for agent006.
This is an evolution of agent005's cognitive_system.py,
integrating the new adaptive modules.
"""

# from ai_interface import GenerativeAIServiceInterface # Now passed in
# from system_actions import SystemActions # Now part of ExternalToolManager or registered tools
from goal_manager_module import GoalStatus # For checking goal status
import os # For path manipulation
import json # For parsing Gemini's response
import re # For cleaning up Gemini's response
import time
from typing import List, Dict, Any, Optional

class AutonomousCognitiveSystem:
    def __init__(self, config_manager, ai_interface, memory_manager,
                 goal_manager, planner, task_scheduler,
                 tool_manager, llm_context_manager, prompt_constructor,
                 adaptive_learning_engine, strategy_controller, self_reflection_analyst,
                 performance_analyzer, self_modification_suite,
                 kb_manager, context_condenser, token_optimizer,
                 logger, operational_log_buffer: List[str]):
        
        self.logger = logger
        self.config_manager = config_manager
        self.ai_interface = ai_interface
        self.memory_manager = memory_manager # Replaces self.ams
        self.goal_manager = goal_manager # Replaces self.dgp
        self.planner = planner
        self.task_scheduler = task_scheduler
        self.tool_manager = tool_manager
        self.llm_context_manager = llm_context_manager
        self.prompt_constructor = prompt_constructor
        self.ale = adaptive_learning_engine
        self.sc = strategy_controller # strategy_controller is self.sc
        self.sms = self_modification_suite
        self.kb_manager = kb_manager
        self.context_condenser = context_condenser
        self.token_optimizer = token_optimizer
        self.self_reflection_analyst = self_reflection_analyst
        self.performance_analyzer = performance_analyzer
        
        self.operational_log_buffer = operational_log_buffer
        # self.system_actions is effectively replaced by tool_manager and registered tools

        self.max_operational_cycles = self.config_manager.get_setting("max_operational_cycles", 10)

        self.logger.info("AutonomousCognitiveSystem (Agent007) initialized with enhanced modules.")

    def initiate_startup_and_goal_definition(self, initial_goal_description=None, initial_goal_priority=100):
        self.logger.info("ACS: Initiating startup and goal definition...")
        if initial_goal_description:
            self.goal_manager.add_goal(initial_goal_description, priority=initial_goal_priority, notes="Initial goal from startup.")
        else:
            # Default goal if none provided by user
            self.goal_manager.add_goal("Achieve enhanced adaptivity and self-improvement.", priority=100, notes="Default startup goal.")
        self._start_autonomous_operational_loop()

    def _build_gemini_prompt(self, current_goal_description: str) -> str:
        """Constructs a detailed prompt for Gemini."""
        # Define available actions (tools) for Gemini
        available_actions_description = """
Available Actions (Tools):
- {"action_type": "goal_completed", "parameters": {"reason": "brief_explanation_why_goal_is_complete"}}
- {"action_type": "sub_task_completed", "parameters": {"task_id": "string (ID of the completed task)", "reason": "string (Brief explanation)"}}
- {"action_type": "no_action_possible", "parameters": {"reason": "brief_explanation_why_no_action"}}
- {"action_type": "clarify_task", "parameters": {"question": "string (Your question for clarification)"}}
"""
        tool_descs = []
        for name, info in self.tool_manager.list_available_tools().items():
            params_str = ", ".join([f'"{pname}": "{ptype}"' for pname, ptype in info.get('parameters_schema', {}).items()])
            tool_descs.append(f'- {{"action_type": "{name}", "description": "{info["description"]}", "parameters": {{{params_str}}}}}')
        available_actions_description += "\n".join(tool_descs)

        # Memory summary using StructuredMemoryManager (placeholder search)
        # A more sophisticated summary would be generated by ContextualMemoryCondenserAI
        recent_events = self.memory_manager.search_memory_placeholder("event_") # Get recent events
        memory_summary_str = f"Recent events in memory: {len(recent_events)} relevant events found. "
        if recent_events:
            # Convert dict values to string for preview
            # Assuming recent_events is a dict of dicts.
            # We need to get the actual event dictionaries.
            event_list = list(recent_events.values()) if isinstance(recent_events, dict) else recent_events
            if event_list and isinstance(event_list[0], dict):
                 last_event = event_list[-1]
                 memory_summary_str += f"Last event type: {last_event.get('type', 'N/A')}, Outcome: {last_event.get('outcome', 'N/A')}."
            else:
                 memory_summary_str += "Could not parse last event details."
        
        # Use ContextualMemoryCondenserAI for a better summary if possible
        condensed_memory = self.context_condenser.condense_information(
            information_type="recent_memory_summary",
            data=list(recent_events.values()) if recent_events else [], # Pass list of event dicts
            target_token_count=150, # Example token count
            relevance_query=current_goal_description
        )

        # Recent logs
        log_context_limit = 20 # Number of recent log lines to include
        recent_logs = "\n".join(list(self.operational_log_buffer)[-log_context_limit:])
        project_root_path = self.config_manager.get_setting("project_root", "the current working directory")

        # Use DynamicPromptConstructor
        prompt_components = {
            'system_message': self.config_manager.get_setting("llm.system_prompt_template", f"You are {self.config_manager.get_setting('agent_name', 'Agent007')}, an autonomous AI."),
            'user_query': current_goal_description, # The current task/goal
            'task_instructions': f"Your current primary goal is: \"{current_goal_description}\". Your objective is to decide the single best next action to take towards achieving this goal. Respond ONLY with a JSON object specifying 'action_type' and 'parameters'.",
            'available_tools_and_actions': available_actions_description,
            'working_environment_info': f"Your primary working directory (project root) is: \"{project_root_path}\". When creating files or folders, unless a full absolute path is specified, create them relative to this project root.",
            'memory_summary': condensed_memory or memory_summary_str, # Prefer condensed
            'recent_operational_logs': f"--- LOG START ---\n{recent_logs}\n--- LOG END ---",
            'history': self.llm_context_manager.get_context() # Get conversation history
        }

        # Define priority for prompt components
        priority_order = [
            'user_query', 'task_instructions', 'system_message', 
            'available_tools_and_actions', 'working_environment_info',
            'history', 'memory_summary', 'recent_operational_logs'
        ]
        
        max_prompt_tokens = self.config_manager.get_setting("llm.model_max_prompt_tokens", 4000)

        final_prompt = self.prompt_constructor.build_and_optimize_prompt(
            components=prompt_components,
            max_tokens=max_prompt_tokens,
            priority_order=priority_order
        )

        self.logger.debug(f"ACS: Built prompt for Gemini (first 300 chars):\n{final_prompt[:300]}...")
        return final_prompt

    def _start_autonomous_operational_loop(self):
        self.logger.info("ACS: Starting autonomous operational loop...")
        
        cycles = 0
        while cycles < self.max_operational_cycles:
            cycles += 1
            self.logger.info(f"\n--- ACS Operational Cycle: {cycles}/{self.max_operational_cycles} ---")

            current_goal_obj = self.goal_manager.get_next_goal_placeholder() # Gets highest priority PENDING, checks deps

            if not current_goal_obj:
                active_goals = self.goal_manager.list_goals(GoalStatus.ACTIVE)
                if active_goals:
                    current_goal_obj = sorted(active_goals, key=lambda g: g.get("priority", 0), reverse=True)[0]
                    self.logger.info(f"No new pending goals. Continuing with active goal: {current_goal_obj['description']}")
                else:
                    self.logger.info("ACS: No pending or active goals. Operational loop idling or concluding.")
                    # Optionally, create a self-reflection/new goal generation task here
                    if not self.goal_manager.list_goals(): # No goals at all
                        new_goal_id = self.goal_manager.add_goal("Self-diagnose and determine next objectives.", priority=200, notes="Auto-generated due to idleness.")
                        current_goal_obj = self.goal_manager.get_goal(new_goal_id)
                        self.logger.info(f"Generated new self-diagnosis goal: {current_goal_obj['description']}")
                    else:
                        break # Exit loop if there are goals but none are actionable
            
            if not current_goal_obj: # Still no goal
                self.logger.error("ACS: Failed to obtain or generate a current goal. Stopping.")
                break

            current_goal_id = current_goal_obj['id']
            current_goal_desc = current_goal_obj['description']

            if current_goal_obj['status'] == GoalStatus.PENDING.value:
                self.goal_manager.update_goal_status(current_goal_id, GoalStatus.ACTIVE, "Goal selected for execution.")
            
            self.logger.info(f"ACS: Current Goal (ID: {current_goal_id}): '{current_goal_desc}' (Priority: {current_goal_obj['priority']}, Status: {current_goal_obj['status']})")

            # TODO: Integrate HierarchicalPlanner and TaskScheduler here if goal is complex
            # For now, assume goal_description is the current task
            task_to_execute_desc = current_goal_desc
            current_task_id_for_llm = f"goal_{current_goal_id}" # Simplified task ID

            # Add current task to LLM context
            self.llm_context_manager.add_message("user", f"My current task is: {task_to_execute_desc}")

            prompt = self._build_gemini_prompt(task_to_execute_desc)
            gemini_response_str = self.ai_interface.generate_text(prompt)

            action_succeeded = False
            action_result_message = "No action determined or LLM error."
            parsed_action_data = None

            if not gemini_response_str or gemini_response_str.startswith("ERROR:"):
                action_result_message = f"LLM interaction failed: {gemini_response_str}"
                self.logger.error(f"ACS: {action_result_message}")
                self.goal_manager.update_goal_status(current_goal_id, GoalStatus.FAILED, action_result_message)
            else:
                try:
                    cleaned_response_str = gemini_response_str.strip()
                    match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", cleaned_response_str, re.DOTALL | re.IGNORECASE)
                    json_to_parse = match.group(1) if match else cleaned_response_str
                    
                    parsed_action_data = json.loads(json_to_parse)
                    action_type = parsed_action_data.get("action_type")
                    action_params = parsed_action_data.get("parameters", {})
                    self.logger.info(f"ACS: LLM proposed action: {action_type} with params: {action_params}")

                    self.llm_context_manager.add_message("assistant", f"Action: {action_type}, Params: {json.dumps(action_params)}")

                    if action_type == "goal_completed":
                        reason = action_params.get("reason", "LLM determined goal is complete.")
                        self.goal_manager.update_goal_status(current_goal_id, GoalStatus.COMPLETED, reason)
                        action_result_message = f"Goal '{current_goal_desc}' marked as completed. Reason: {reason}"
                        action_succeeded = True
                    
                    elif action_type == "sub_task_completed": # Basic handling
                        task_id_completed = action_params.get("task_id", "unknown_sub_task")
                        reason = action_params.get("reason", "LLM determined sub-task is complete.")
                        # self.task_scheduler.update_task_status(task_id_completed, "completed") # If using scheduler
                        action_result_message = f"Sub-task '{task_id_completed}' marked as completed. Reason: {reason}"
                        action_succeeded = True # Assume progress

                    elif action_type == "clarify_task":
                        question = action_params.get("question", "The LLM needs clarification.")
                        self.goal_manager.update_goal_status(current_goal_id, GoalStatus.PAUSED, f"Needs clarification: {question}")
                        action_result_message = f"Task paused for clarification: {question}"
                        action_succeeded = False; break # Exit loop to await clarification
                    
                    elif action_type == "no_action_possible":
                        reason = action_params.get("reason", "LLM determined no action is possible.")
                        self.goal_manager.update_goal_status(current_goal_id, GoalStatus.FAILED, f"No action possible: {reason}")
                        action_result_message = f"No action possible. Reason: {reason}"
                        action_succeeded = False
                    
                    elif self.tool_manager.available_tools.get(action_type):
                        tool_result = self.tool_manager.use_tool(action_type, **action_params)
                        action_result_message = f"Tool '{action_type}' executed. Result (preview): {str(tool_result)[:200]}"
                        self.memory_manager.store_data(f"tool_result_{action_type}_{time.time()}", {"goal_id": current_goal_id, "task_desc": task_to_execute_desc, "result": tool_result, "params": action_params})
                        if isinstance(tool_result, str) and tool_result.startswith("Error:"):
                            action_succeeded = False
                            action_result_message += f" - Error: {tool_result}"
                        elif isinstance(tool_result, dict) and tool_result.get("success") is False:
                            action_succeeded = False
                            action_result_message += f" - Error: {tool_result.get('error', 'Tool reported failure.')}"
                        else:
                            action_succeeded = True
                    else:
                        action_result_message = f"Unknown action_type '{action_type}'."
                        action_succeeded = False

                except json.JSONDecodeError as e:
                    action_result_message = f"Failed to decode LLM's JSON response: {e}. Original: '{gemini_response_str}'"
                    action_succeeded = False
                except Exception as e:
                    action_result_message = f"Error processing LLM's action: {e}"
                    self.logger.error(f"ACS: {action_result_message}", exc_info=True)
                    action_succeeded = False
            
            self.logger.info(f"ACS: Action outcome: {action_result_message}")

            # Store event
            event_data = {"type": "action_attempt", "goal_id": current_goal_id, "task_description": task_to_execute_desc, 
                          "llm_action": parsed_action_data, "outcome": "success" if action_succeeded else "failure", 
                          "result_message": action_result_message, "timestamp": time.time()}
            self.memory_manager.store_data(f"event_{current_task_id_for_llm}_{time.time()}", event_data)

            # Self-reflection and performance analysis
            current_goal_state_for_reflection = self.goal_manager.get_goal(current_goal_id)
            reflection = self.self_reflection_analyst.analyze_recent_performance([event_data], current_goal_state_for_reflection)
            if reflection.get("suggestions"): self.logger.info(f"ACS Self-Reflection suggestions: {reflection['suggestions']}")

            log_analysis = self.performance_analyzer.analyze_log_entries_placeholder(list(self.operational_log_buffer))
            if log_analysis.get("error_count",0) > 0 or log_analysis.get("warning_count",0) > 0:
                 self.logger.info(f"ACS Log Analysis: Errors: {log_analysis['error_count']}, Warnings: {log_analysis['warning_count']}")

            # If goal completed or failed, loop will pick new one or exit
            if current_goal_obj['status'] in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value, GoalStatus.PAUSED.value]:
                self.logger.info(f"Goal '{current_goal_desc}' is now {current_goal_obj['status']}. Moving to next cycle.")
                if current_goal_obj['status'] == GoalStatus.PAUSED.value: break # Exit loop if paused
            
            time.sleep(self.config_manager.get_setting("operational_loop_delay_seconds", 1))

        self.logger.info(f"ACS: Autonomous operational loop completed {cycles} cycles or reached max limit.")

        try:
            # Attempt to parse Gemini's response as JSON
            # Clean the response: Gemini might wrap JSON in ```json ... ```
            cleaned_response_str = gemini_response_str.strip()
            # Regex to extract JSON from potential markdown code blocks
            match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", cleaned_response_str, re.DOTALL | re.IGNORECASE)
            if match:
                json_to_parse = match.group(1)
            else:
                json_to_parse = cleaned_response_str # Assume it's raw JSON if no backticks

            response_data = json.loads(json_to_parse)
            action_type = response_data.get("action_type")
            action_params = response_data.get("parameters", {})
            self.logger.info(f"ACS: Gemini proposed action: {action_type} with params: {action_params}")

            if action_type == "create_folder":
                folder_path = action_params.get("folder_path")
                if folder_path:
                    result = self.system_actions.create_folder(folder_path)
                    action_executed_successfully = result["success"]
                    action_outcome_message = f"Folder creation at '{folder_path}': {'Success' if result['success'] else 'Failed: ' + result.get('error', 'Unknown error')}"
                else:
                    action_outcome_message = "Missing 'folder_path' for create_folder action."
            
            elif action_type == "create_file":
                file_path = action_params.get("file_path")
                content = action_params.get("content", "")
                if file_path:
                    result = self.system_actions.create_file(file_path, content)
                    action_executed_successfully = result["success"]
                    action_outcome_message = f"File creation at '{file_path}': {'Success' if result['success'] else 'Failed: ' + result.get('error', 'Unknown error')}"
                else:
                    action_outcome_message = "Missing 'file_path' for create_file action."

            elif action_type == "execute_code":
                code_string = action_params.get("code_string")
                if code_string:
                    result = self.sms.execute_sandboxed_code(code_string, human_approval_required=self.config.get("human_approval_required_for_code_execution", True))
                    action_executed_successfully = result["success"]
                    action_outcome_message = f"Code execution: {'Success, output: ' + str(result.get('output'))[:200] if result['success'] else 'Failed: ' + result.get('error', 'Unknown error')}"
                else:
                    action_outcome_message = "Missing 'code_string' for execute_code action."

            elif action_type == "goal_completed":
                action_executed_successfully = True # The "action" is acknowledging completion
                action_outcome_message = action_params.get("reason", "Gemini determined the goal is complete.")
            
            elif action_type == "no_action_possible":
                action_executed_successfully = False # No action was taken that progresses the goal
                action_outcome_message = action_params.get("reason", "Gemini determined no further action is possible or appropriate for this goal.")

            else:
                action_outcome_message = f"Unknown or unsupported action_type '{action_type}' received from Gemini."
                action_executed_successfully = False

        except json.JSONDecodeError as e:
            action_outcome_message = f"Failed to decode Gemini's JSON response: {e}. Original response was: {gemini_response_str}"
            self.logger.error(f"ACS: {action_outcome_message}")
            action_executed_successfully = False
        except Exception as e:
            action_outcome_message = f"Error processing Gemini's action: {e}"
            self.logger.error(f"ACS: {action_outcome_message}", exc_info=True)
            action_executed_successfully = False

        # Update Goal Status based on action outcome
        if action_executed_successfully and action_type == "goal_completed":
            self.dgp.update_goal_status(current_goal_desc, "completed", action_outcome_message)
        elif action_executed_successfully:
            # If an action was successful but it's not explicitly "goal_completed",
            # the goal might still be active, or it might be completed.
            # For simplicity now, we'll assume a successful action means the current interpretation of the goal is done.
            # A more advanced system would have Gemini explicitly state if the overall goal is met.
            self.logger.info(f"ACS: Action '{action_type}' successful. Outcome: {action_outcome_message}. Marking goal '{current_goal_desc}' as completed for now.")
            self.dgp.update_goal_status(current_goal_desc, "completed", f"Action '{action_type}' executed successfully. {action_outcome_message}")
        else:
            self.dgp.update_goal_status(current_goal_desc, "failed", action_outcome_message)

        self.logger.info(f"ACS: Operational loop cycle complete for goal '{current_goal_desc}'. Final Outcome: {action_outcome_message}")